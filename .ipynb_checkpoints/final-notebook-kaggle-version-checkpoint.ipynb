{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.009602,
     "end_time": "2023-02-21T23:32:28.675688",
     "exception": false,
     "start_time": "2023-02-21T23:32:28.666086",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Facial Expression Recognition | VGG19 Model - FER2013 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.00803,
     "end_time": "2023-02-21T23:32:28.775887",
     "exception": false,
     "start_time": "2023-02-21T23:32:28.767857",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 8.188704,
     "end_time": "2023-02-21T23:32:36.972552",
     "exception": false,
     "start_time": "2023-02-21T23:32:28.783848",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "import scikitplot\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv2D, GlobalAveragePooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization, Activation\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-29T06:13:44.132285Z",
     "iopub.status.busy": "2023-06-29T06:13:44.131210Z",
     "iopub.status.idle": "2023-06-29T06:13:44.139785Z",
     "shell.execute_reply": "2023-06-29T06:13:44.138594Z",
     "shell.execute_reply.started": "2023-06-29T06:13:44.132217Z"
    }
   },
   "source": [
    "## Extract data from dataset and rehshape data back to 2D dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 5.936801,
     "end_time": "2023-02-21T23:32:42.918178",
     "exception": false,
     "start_time": "2023-02-21T23:32:36.981377",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('fer-2013/fer2013/fer2013.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 39.660137,
     "end_time": "2023-02-21T23:33:30.286412",
     "exception": false,
     "start_time": "2023-02-21T23:32:50.626275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_array = df.pixels.apply(lambda x: np.array(x.split(' ')).reshape(48, 48).astype('float32'))\n",
    "img_array = np.stack(img_array, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Data to RBG (compatiable with VGG 19), also normalization using Min Max Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.912211,
     "end_time": "2023-02-21T23:33:31.250950",
     "exception": false,
     "start_time": "2023-02-21T23:33:30.338739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_features = []\n",
    "\n",
    "for i in range(len(img_array)):\n",
    "    temp = cv2.cvtColor(img_array[i], cv2.COLOR_GRAY2RGB)\n",
    "    img_features.append(temp)\n",
    "\n",
    "img_features = np.array(img_features)\n",
    "print(img_features.shape)\n",
    "\n",
    "img_features = img_features/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.22468,
     "end_time": "2023-02-21T23:33:31.489635",
     "exception": false,
     "start_time": "2023-02-21T23:33:31.264955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pyplot.imshow((img_features[0]*255).astype(np.uint8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.028227,
     "end_time": "2023-02-21T23:33:31.531431",
     "exception": false,
     "start_time": "2023-02-21T23:33:31.503204",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "img_labels = le.fit_transform(df.emotion)\n",
    "img_labels = np_utils.to_categorical(img_labels)\n",
    "img_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013334,
     "end_time": "2023-02-21T23:33:31.594833",
     "exception": false,
     "start_time": "2023-02-21T23:33:31.581499",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Splitting the data into training and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.552102,
     "end_time": "2023-02-21T23:33:32.159866",
     "exception": false,
     "start_time": "2023-02-21T23:33:31.607764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_valid, X_test, y_train_valid, y_test = train_test_split(img_features, \n",
    "                                                      img_labels, \n",
    "                                                      shuffle = True, \n",
    "                                                      stratify = img_labels, \n",
    "                                                      test_size = 0.1, \n",
    "                                                      random_state = 42)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_valid, \n",
    "                                                      y_train_valid, \n",
    "                                                      shuffle = True, \n",
    "                                                      stratify = y_train_valid, \n",
    "                                                      test_size = 0.11, \n",
    "                                                      random_state = 42)\n",
    "X_train.shape, X_valid.shape,X_test.shape, y_train.shape, y_valid.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.imshow((X_test[95]*255).astype(np.uint8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this code if you only want to split into training and validation data\n",
    "# X_train,X_valid, y_train, y_valid = train_test_split(img_features, \n",
    "#                                                       img_labels, \n",
    "#                                                       shuffle = True, \n",
    "#                                                       stratify = img_labels, \n",
    "#                                                       test_size = 0.1, \n",
    "#                                                       random_state = 42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and import weight from VGG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 4.097025,
     "end_time": "2023-02-21T23:33:36.695651",
     "exception": false,
     "start_time": "2023-02-21T23:33:32.598626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Downlaod VGG model with weight except 3 fully connected layers\n",
    "\n",
    "vgg = tf.keras.applications.VGG19(weights = 'imagenet',\n",
    "                                  include_top = False,\n",
    "                                  input_shape = (48, 48, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.025758,
     "end_time": "2023-02-21T23:33:36.917291",
     "exception": false,
     "start_time": "2023-02-21T23:33:36.891533",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#This function will create a model based on CNN blocks from VGG 19.\n",
    "def build_model(bottom_model, classes):\n",
    "    model = bottom_model.layers[-2].output\n",
    "    model = GlobalMaxPooling2D()(model)\n",
    "    model = Dense(classes, activation = 'softmax', name = 'out_layer')(model)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.122994,
     "end_time": "2023-02-21T23:33:37.057333",
     "exception": false,
     "start_time": "2023-02-21T23:33:36.934339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_classes = 7\n",
    "head = build_model(vgg, num_classes)\n",
    "\n",
    "model = Model(inputs = vgg.input, outputs = head)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not freeze any layer\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "for layer in model.layers:\n",
    "    print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019708,
     "end_time": "2023-02-21T23:33:37.099105",
     "exception": false,
     "start_time": "2023-02-21T23:33:37.079397",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Early Stopping after no improvement for 11 epochs and Reduce Learning Rate Scheduler \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.028579,
     "end_time": "2023-02-21T23:33:37.148178",
     "exception": false,
     "start_time": "2023-02-21T23:33:37.119599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor = 'val_accuracy', \n",
    "                               min_delta = 0.00005, \n",
    "                               patience = 11,\n",
    "                               verbose = 1, \n",
    "                               restore_best_weights = True,)\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(monitor = 'val_accuracy', \n",
    "                                 factor = 0.5, \n",
    "                                 patience = 7,\n",
    "                                 min_lr = 1e-7,\n",
    "                                 verbose = 1,)\n",
    "\n",
    "callbacks = [early_stopping,lr_scheduler,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022724,
     "end_time": "2023-02-21T23:33:37.190869",
     "exception": false,
     "start_time": "2023-02-21T23:33:37.168145",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Apply data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.355921,
     "end_time": "2023-02-21T23:33:37.573936",
     "exception": false,
     "start_time": "2023-02-21T23:33:37.218015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rotation_range = 15,\n",
    "                                   width_shift_range = 0.15,\n",
    "                                   height_shift_range = 0.15,\n",
    "                                   shear_range = 0.15,\n",
    "                                   zoom_range = 0.15,\n",
    "                                   horizontal_flip = True,)\n",
    "train_datagen.fit(X_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Focal loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def focal_loss(gamma=2):\n",
    "    def loss(y_true, y_pred):\n",
    "        ce_loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred, from_logits=True)\n",
    "        pt = tf.math.exp(-ce_loss)\n",
    "        focal_loss = tf.pow(1 - pt, gamma) * ce_loss\n",
    "        return focal_loss\n",
    "    return loss\n",
    "gamma = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling and Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size of 32 performs the best.\n",
    "batch_size = 32 \n",
    "epochs = 60\n",
    "optims = [optimizers.Adam(learning_rate = 0.0001, beta_1 = 0.9, beta_2 = 0.999),]\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = optims[0],\n",
    "              metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 1530.626395,
     "end_time": "2023-02-21T23:59:08.278254",
     "exception": false,
     "start_time": "2023-02-21T23:33:37.651859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_datagen.flow(X_train, \n",
    "                                       y_train, \n",
    "                                       batch_size = batch_size),\n",
    "                                       validation_data = (X_valid, y_valid),\n",
    "                                       steps_per_epoch = len(X_train) / batch_size,\n",
    "\n",
    "                                       epochs = epochs,\n",
    "                                       callbacks = callbacks,\n",
    "#                                        use_multiprocessing = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 1.983505,
     "end_time": "2023-02-21T23:59:11.647964",
     "exception": false,
     "start_time": "2023-02-21T23:59:09.664459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model_yaml = model.to_json()\n",
    "# with open(\"model.yaml\", \"w\") as yaml_file:\n",
    "#     yaml_file.write(model_yaml)\n",
    "    \n",
    "# model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 2.74917,
     "end_time": "2023-02-21T23:59:15.824774",
     "exception": false,
     "start_time": "2023-02-21T23:59:13.075604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Graph drawing \n",
    "sns.set()\n",
    "fig = pyplot.figure(0, (12, 4))\n",
    "\n",
    "ax = pyplot.subplot(1, 2, 1)\n",
    "sns.lineplot(x=history.epoch, y=history.history['accuracy'], label='train')\n",
    "sns.lineplot(x=history.epoch, y=history.history['val_accuracy'], label='valid')\n",
    "pyplot.title('Accuracy')\n",
    "pyplot.tight_layout()\n",
    "\n",
    "ax = pyplot.subplot(1, 2, 2)\n",
    "sns.lineplot(x=history.epoch, y=history.history['loss'], label='train')\n",
    "sns.lineplot(x=history.epoch, y=history.history['val_loss'], label='valid')\n",
    "pyplot.title('Loss')\n",
    "pyplot.tight_layout()\n",
    "\n",
    "pyplot.savefig('epoch_history_dcnn.png')\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 4.659401,
     "end_time": "2023-02-21T23:59:25.995629",
     "exception": false,
     "start_time": "2023-02-21T23:59:21.336228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Confusion matrix for testing data\n",
    "print(\"This is for testing data\")\n",
    "yhat_test = np.argmax(model.predict(X_test), axis=1)\n",
    "scikitplot.metrics.plot_confusion_matrix(np.argmax(y_test, axis=1), yhat_test, figsize=(7,7))\n",
    "pyplot.savefig(\"confusion_matrix_dcnn.png\")\n",
    "\n",
    "print(f'total wrong validation predictions: {np.sum(np.argmax(y_test, axis=1) != yhat_test)}\\n\\n')\n",
    "report = classification_report(np.argmax(y_test, axis=1), yhat_test, digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion mateix for validation data\n",
    "print(\"this is for validationd data\")\n",
    "yhat_valid = np.argmax(model.predict(X_valid), axis=1)\n",
    "scikitplot.metrics.plot_confusion_matrix(np.argmax(y_valid, axis=1), yhat_valid, figsize=(7,7))\n",
    "pyplot.savefig(\"confusion_matrix_dcnn.png\")\n",
    "\n",
    "print(f'total wrong validation predictions: {np.sum(np.argmax(y_valid, axis=1) != yhat_valid)}\\n\\n')\n",
    "report = classification_report(np.argmax(y_valid, axis=1), yhat_valid, digits=4)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
